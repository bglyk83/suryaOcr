import os
import json
import time
from PIL import Image
import numpy as np
from collections import defaultdict
import re
from surya.model.detection.segformer import load_model as load_det_model, load_processor as load_det_processor
from surya.model.recognition.model import load_model as load_rec_model
from surya.model.recognition.processor import load_processor as load_rec_processor
from surya.ocr import run_ocr

def calculate_cer(pred, true):
    """Character Error Rate ê³„ì‚°"""
    if not true:
        return 1.0 if pred else 0.0
    
    # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
    pred_clean = re.sub(r'[^\w\sê°€-í£]', '', pred.lower())
    true_clean = re.sub(r'[^\w\sê°€-í£]', '', true.lower())
    
    if not true_clean:
        return 1.0 if pred_clean else 0.0
    
    # Levenshtein distance ê³„ì‚°
    m, n = len(true_clean), len(pred_clean)
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    for i in range(m + 1):
        dp[i][0] = i
    for j in range(n + 1):
        dp[0][j] = j
    
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if true_clean[i-1] == pred_clean[j-1]:
                dp[i][j] = dp[i-1][j-1]
            else:
                dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1
    
    return dp[m][n] / len(true_clean)

def calculate_wer(pred, true):
    """Word Error Rate ê³„ì‚°"""
    if not true:
        return 1.0 if pred else 0.0
    
    # ë‹¨ì–´ë¡œ ë¶„ë¦¬
    pred_words = re.findall(r'\w+', pred.lower())
    true_words = re.findall(r'\w+', true.lower())
    
    if not true_words:
        return 1.0 if pred_words else 0.0
    
    # Levenshtein distance ê³„ì‚°
    m, n = len(true_words), len(pred_words)
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    for i in range(m + 1):
        dp[i][0] = i
    for j in range(n + 1):
        dp[0][j] = j
    
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if true_words[i-1] == pred_words[j-1]:
                dp[i][j] = dp[i-1][j-1]
            else:
                dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1
    
    return dp[m][n] / len(true_words)

def extract_ground_truth(label_path):
    """JSON íŒŒì¼ì—ì„œ ground truth í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    with open(label_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    texts = []
    for ann in data["annotations"]:
        for poly in ann.get("polygons", []):
            text = poly.get("text", "")
            if text.strip():
                texts.append(text.strip())
    
    return texts

def benchmark_ocr():
    """OCR ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print("=== Surya OCR ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ===\n")
    
    # ëª¨ë¸ ë¡œë“œ
    print("ëª¨ë¸ ë¡œë”© ì¤‘...")
    start_time = time.time()
    det_model = load_det_model()
    det_processor = load_det_processor()
    rec_model = load_rec_model()
    rec_processor = load_rec_processor()
    model_load_time = time.time() - start_time
    print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_load_time:.2f}ì´ˆ\n")
    
    # ë°ì´í„° ì¤€ë¹„
    DATA_DIR = "./data"
    IMG_DIR = os.path.join(DATA_DIR, "images")
    LABEL_DIR = os.path.join(DATA_DIR, "labels")
    
    image_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    print(f"ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸\n")
    
    # ì„±ëŠ¥ ì§€í‘œ ì´ˆê¸°í™”
    total_cer = 0
    total_wer = 0
    total_texts = 0
    total_detection_time = 0
    total_recognition_time = 0
    total_processing_time = 0
    confidence_scores = []
    
    results_by_image = []
    
    for i, img_file in enumerate(image_files):
        print(f"ì²˜ë¦¬ ì¤‘: {img_file} ({i+1}/{len(image_files)})")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        img_path = os.path.join(IMG_DIR, img_file)
        image = Image.open(img_path).convert("RGB")
        
        # Ground truth ë¡œë“œ
        label_file = img_file.rsplit('.', 1)[0] + '.json'
        label_path = os.path.join(LABEL_DIR, label_file)
        
        if not os.path.exists(label_path):
            print(f"  âš ï¸  ë¼ë²¨ íŒŒì¼ ì—†ìŒ: {label_file}")
            continue
        
        ground_truth_texts = extract_ground_truth(label_path)
        
        # OCR ì‹¤í–‰
        start_time = time.time()
        images = [image]
        languages = [["ko"]]
        
        results = run_ocr(images, languages, det_model, det_processor, rec_model, rec_processor)
        processing_time = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        predicted_texts = []
        confidences = []
        
        for result in results:
            for text_line in result.text_lines:
                predicted_texts.append(text_line.text)
                if text_line.confidence is not None and not np.isnan(text_line.confidence):
                    confidences.append(text_line.confidence)
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        image_cer = 0
        image_wer = 0
        matched_count = 0
        
        # í…ìŠ¤íŠ¸ ë§¤ì¹­ (ê°„ë‹¨í•œ ë°©ë²•)
        for pred_text in predicted_texts:
            best_cer = float('inf')
            best_wer = float('inf')
            
            for gt_text in ground_truth_texts:
                cer = calculate_cer(pred_text, gt_text)
                wer = calculate_wer(pred_text, gt_text)
                
                if cer < best_cer:
                    best_cer = cer
                if wer < best_wer:
                    best_wer = wer
            
            if best_cer < 0.5:  # 50% ì´í•˜ì˜ CERì„ ë§¤ì¹­ìœ¼ë¡œ ê°„ì£¼
                matched_count += 1
            
            image_cer += best_cer
            image_wer += best_wer
        
        if predicted_texts:
            image_cer /= len(predicted_texts)
            image_wer /= len(predicted_texts)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        total_cer += image_cer * len(predicted_texts)
        total_wer += image_wer * len(predicted_texts)
        total_texts += len(predicted_texts)
        total_processing_time += processing_time
        confidence_scores.extend(confidences)
        
        # ì´ë¯¸ì§€ë³„ ê²°ê³¼ ì €ì¥
        results_by_image.append({
            'image': img_file,
            'predicted_count': len(predicted_texts),
            'ground_truth_count': len(ground_truth_texts),
            'cer': image_cer,
            'wer': image_wer,
            'processing_time': processing_time,
            'avg_confidence': np.mean(confidences) if confidences else 0
        })
        
        print(f"  ğŸ“Š ì˜ˆì¸¡: {len(predicted_texts)}ê°œ, ì‹¤ì œ: {len(ground_truth_texts)}ê°œ")
        print(f"  ğŸ“ˆ CER: {image_cer:.3f}, WER: {image_wer:.3f}")
        print(f"  â±ï¸  ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"  ğŸ¯ í‰ê·  ì‹ ë¢°ë„: {np.mean(confidences) if confidences else 0:.3f}\n")
    
    # ì „ì²´ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    if total_texts > 0:
        avg_cer = total_cer / total_texts
        avg_wer = total_wer / total_texts
    else:
        avg_cer = avg_wer = 0
    
    avg_processing_time = total_processing_time / len(image_files)
    avg_confidence = np.mean(confidence_scores) if confidence_scores else 0
    
    # ê²°ê³¼ ì¶œë ¥
    print("=" * 50)
    print(" ì „ì²´ ì„±ëŠ¥ ì§€í‘œ")
    print("=" * 50)
    print(f"  ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
    print(f" ì´ í…ìŠ¤íŠ¸: {total_texts}ê°œ")
    print(f"  ì´ ì²˜ë¦¬ì‹œê°„: {total_processing_time:.2f}ì´ˆ")
    print(f" í‰ê·  ì²˜ë¦¬ì‹œê°„: {avg_processing_time:.2f}ì´ˆ/ì´ë¯¸ì§€")
    print(f" ì²˜ë¦¬ì†ë„: {len(image_files)/total_processing_time:.2f} ì´ë¯¸ì§€/ì´ˆ")
    print()
    print(f" í‰ê·  CER: {avg_cer:.3f}")
    print(f" í‰ê·  WER: {avg_wer:.3f}")
    print(f" í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
    print(f" ì‹ ë¢°ë„ í‘œì¤€í¸ì°¨: {np.std(confidence_scores) if confidence_scores else 0:.3f}")
    print()
    
    # ì´ë¯¸ì§€ë³„ ìƒì„¸ ê²°ê³¼
    print(" ì´ë¯¸ì§€ë³„ ìƒì„¸ ê²°ê³¼")
    print("-" * 50)
    for result in results_by_image:
        print(f"{result['image']:20} | "
              f"ì˜ˆì¸¡: {result['predicted_count']:3d} | "
              f"ì‹¤ì œ: {result['ground_truth_count']:3d} | "
              f"CER: {result['cer']:.3f} | "
              f"WER: {result['wer']:.3f} | "
              f"ì‹œê°„: {result['processing_time']:.2f}s | "
              f"ì‹ ë¢°ë„: {result['avg_confidence']:.3f}")
    
    # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
    print("\n ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€")
    print("-" * 30)
    
    if avg_cer < 0.1:
        cer_grade = "A+ (ìš°ìˆ˜)"
    elif avg_cer < 0.2:
        cer_grade = "A (ì–‘í˜¸)"
    elif avg_cer < 0.3:
        cer_grade = "B (ë³´í†µ)"
    elif avg_cer < 0.5:
        cer_grade = "C (ë¯¸í¡)"
    else:
        cer_grade = "D (ë¶ˆëŸ‰)"
    
    if avg_wer < 0.2:
        wer_grade = "A+ (ìš°ìˆ˜)"
    elif avg_wer < 0.4:
        wer_grade = "A (ì–‘í˜¸)"
    elif avg_wer < 0.6:
        wer_grade = "B (ë³´í†µ)"
    elif avg_wer < 0.8:
        wer_grade = "C (ë¯¸í¡)"
    else:
        wer_grade = "D (ë¶ˆëŸ‰)"
    
    print(f" CER ë“±ê¸‰: {cer_grade}")
    print(f" WER ë“±ê¸‰: {wer_grade}")
    print(f" ì†ë„ ë“±ê¸‰: {'ë¹ ë¦„' if avg_processing_time < 10 else 'ë³´í†µ' if avg_processing_time < 30 else 'ëŠë¦¼'}")
    
    return {
        'avg_cer': avg_cer,
        'avg_wer': avg_wer,
        'avg_processing_time': avg_processing_time,
        'avg_confidence': avg_confidence,
        'total_texts': total_texts,
        'total_images': len(image_files)
    }

if __name__ == "__main__":
    results = benchmark_ocr() 